{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4734ff-fe5f-48bf-bd71-9e5062673d19",
   "metadata": {},
   "source": [
    "## IMPORTANCIA DE CARACTERISTICAS DEL MODELO LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2f78d2-649a-4325-bf2a-52df9868cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 64648, number of negative: 1070767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1135415, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056938 -> initscore=-2.807173\n",
      "[LightGBM] [Info] Start training from score -2.807173\n",
      "\n",
      "Resultados del modelo LightGBM:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9998\n",
      "Precision: 0.9916\n",
      "Recall: 0.9786\n",
      "Specificity: 0.9995\n",
      "F1_Score: 0.9850\n",
      "Accuracy: 0.9983\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[458669    231]\n",
      " [   593  27114]]\n",
      "\n",
      "Importancia de características (ordenadas de mayor a menor):\n",
      "================================================================================\n",
      "                               feature importance_percentage\n",
      "22               Deuda_Sist_Financiero               8.2734%\n",
      "23                  SituacionPonderada               7.8095%\n",
      "27                          TotalDeuda               7.5203%\n",
      "17         Importe_PrestamosPersonales               6.7134%\n",
      "20  Plazo_Promedio_PrestamosPersonales               5.8801%\n",
      "1                              Nro Doc               5.6658%\n",
      "31                      Tasa_Ponderada               5.2275%\n",
      "8                   CA_SaldoPromedio_$               4.8025%\n",
      "6                           Antiguedad               4.3448%\n",
      "5                                 Edad               4.2504%\n",
      "7                    CA_acreditaciones               4.1411%\n",
      "28                           Localidad               3.9603%\n",
      "15                  TC_Tuya_SaldoPesos               3.8730%\n",
      "32              Acreditaciones_sueldos               3.8713%\n",
      "33                Otras_Acreditaciones               3.8148%\n",
      "19    Plazo_Maximo_PrestamosPersonales               3.0397%\n",
      "0                                  Suc               2.5838%\n",
      "2                              Periodo               2.4418%\n",
      "16        Cantidad_PrestamosPersonales               2.0785%\n",
      "21                   Sit_Maxima_CENDEU               1.9259%\n",
      "26                 TasaBADLAR_Promedio               1.4594%\n",
      "24                    InflaciónMensual               1.3131%\n",
      "13                  TC_Visa_SaldoPesos               1.1314%\n",
      "25                RemuneracionPromedio               0.8298%\n",
      "11                TC_Master_SaldoPesos               0.7681%\n",
      "3                             Segmento               0.5115%\n",
      "18            Tasa_PrestamosPersonales               0.4339%\n",
      "14                    TC_Tuya_Cantidad               0.3131%\n",
      "4                               Genero               0.2857%\n",
      "12                    TC_Visa_Cantidad               0.2778%\n",
      "10                  TC_Master_Cantidad               0.1702%\n",
      "9                 CA_SaldoPromedio_U$s               0.1296%\n",
      "30                          Plazo Fijo               0.1093%\n",
      "29                  Cantidad_PlazoFijo               0.0494%\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/lightgbm_analysis_results_20241212_010416\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamos2.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "model = lgb.LGBMClassifier(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    num_leaves=127,\n",
    "    n_estimators=900,\n",
    "    min_child_samples=10,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo LightGBM...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/lightgbm_analysis_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Análisis de importancia de características\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "})\n",
    "feature_importance['importance_percentage'] = (feature_importance['importance'] / \n",
    "                                            feature_importance['importance'].sum()) * 100\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# 1. Graficar importancia de todas las características\n",
    "plt.figure(figsize=(15, len(feature_importance) * 0.3))\n",
    "sns.barplot(x='importance_percentage', y='feature', data=feature_importance)\n",
    "plt.title('Importancia de Características - LightGBM', fontsize=14)\n",
    "plt.xlabel('Importancia (%)', fontsize=12)\n",
    "plt.ylabel('Característica', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - LightGBM', fontsize=14)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.xlabel('Predicho', fontsize=12)\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, 'b-', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos', fontsize=12)\n",
    "plt.ylabel('Tasa de Verdaderos Positivos', fontsize=12)\n",
    "plt.title('Curva ROC - LightGBM', fontsize=14)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{result_dir}/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, \n",
    "        color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - LightGBM', fontsize=14)\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "    'model_name': 'LightGBM',\n",
    "    'hyperparameters': {\n",
    "        'subsample': 0.6,\n",
    "        'reg_lambda': 0.1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'num_leaves': 127,\n",
    "        'n_estimators': 900,\n",
    "        'min_child_samples': 10,\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'colsample_bytree': 0.6\n",
    "    },\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'feature_importance': {\n",
    "        'features': feature_importance['feature'].tolist(),\n",
    "        'importance_scores': feature_importance['importance'].tolist(),\n",
    "        'importance_percentages': feature_importance['importance_percentage'].tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "feature_importance.to_csv(f'{result_dir}/feature_importance.csv', index=False)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados del modelo LightGBM:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nImportancia de características (ordenadas de mayor a menor):\")\n",
    "print(\"=\"*80)\n",
    "print(feature_importance[['feature', 'importance_percentage']].to_string(\n",
    "    formatters={'importance_percentage': '{:.4f}%'.format}\n",
    "))\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fed176-0467-43b3-8b27-f87674fe1543",
   "metadata": {},
   "source": [
    "## IMPORTANCIA DE CARACTERISTICAS MEDIANTE LA APLICACION DE LA TECNICA SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def5618b-e01a-4407-ad61-fd6e7b83fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 64648, number of negative: 1070767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.249859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1135415, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056938 -> initscore=-2.807173\n",
      "[LightGBM] [Info] Start training from score -2.807173\n",
      "Calculando valores SHAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:448: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn('LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando gráficos de dependencia para las variables más importantes...\n",
      "\n",
      "Importancia de variables según SHAP (ordenadas de mayor a menor):\n",
      "================================================================================\n",
      "                               feature importance_percentage\n",
      "23                  SituacionPonderada              24.2148%\n",
      "20  Plazo_Promedio_PrestamosPersonales              14.2736%\n",
      "19    Plazo_Maximo_PrestamosPersonales               8.1508%\n",
      "32              Acreditaciones_sueldos               5.8079%\n",
      "21                   Sit_Maxima_CENDEU               4.5797%\n",
      "26                 TasaBADLAR_Promedio               4.2218%\n",
      "7                    CA_acreditaciones               3.6239%\n",
      "8                   CA_SaldoPromedio_$               3.4816%\n",
      "27                          TotalDeuda               3.4127%\n",
      "17         Importe_PrestamosPersonales               3.4086%\n",
      "31                      Tasa_Ponderada               3.1231%\n",
      "22               Deuda_Sist_Financiero               2.7932%\n",
      "16        Cantidad_PrestamosPersonales               2.7018%\n",
      "28                           Localidad               2.1911%\n",
      "33                Otras_Acreditaciones               1.8543%\n",
      "15                  TC_Tuya_SaldoPesos               1.4117%\n",
      "2                              Periodo               1.3657%\n",
      "5                                 Edad               1.2205%\n",
      "6                           Antiguedad               1.0695%\n",
      "1                              Nro Doc               1.0504%\n",
      "0                                  Suc               0.9656%\n",
      "13                  TC_Visa_SaldoPesos               0.8232%\n",
      "11                TC_Master_SaldoPesos               0.7008%\n",
      "24                    InflaciónMensual               0.6175%\n",
      "14                    TC_Tuya_Cantidad               0.5175%\n",
      "25                RemuneracionPromedio               0.4688%\n",
      "3                             Segmento               0.4170%\n",
      "4                               Genero               0.3831%\n",
      "12                    TC_Visa_Cantidad               0.2755%\n",
      "10                  TC_Master_Cantidad               0.2553%\n",
      "18            Tasa_PrestamosPersonales               0.2062%\n",
      "30                          Plazo Fijo               0.1483%\n",
      "29                  Cantidad_PlazoFijo               0.1334%\n",
      "9                 CA_SaldoPromedio_U$s               0.1313%\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/lightgbm_shap_analysis_20241212_010803\n",
      "\n",
      "Visualizaciones generadas:\n",
      "1. shap_importance_bar.png - Importancia general de variables\n",
      "2. shap_importance_beeswarm.png - Distribución del impacto de variables\n",
      "3. Gráficos de dependencia para las top 5 variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamos2.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo\n",
    "model = lgb.LGBMClassifier(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    num_leaves=127,\n",
    "    n_estimators=900,\n",
    "    min_child_samples=10,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo LightGBM...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/lightgbm_shap_analysis_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Calcular valores SHAP\n",
    "print(\"Calculando valores SHAP...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# 1. Summary Plot\n",
    "plt.figure(figsize=(12, len(X.columns) * 0.3))\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Importancia de Variables (SHAP)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/shap_importance_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Summary Plot (Beeswarm)\n",
    "plt.figure(figsize=(12, len(X.columns) * 0.3))\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "plt.title(\"Impacto de Variables en la Predicción (SHAP)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/shap_importance_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Calcular importancia media absoluta SHAP\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.abs(shap_values).mean(0),\n",
    "    'importance_percentage': 100 * np.abs(shap_values).mean(0) / np.abs(shap_values).mean(0).sum()\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Guardar resultados\n",
    "feature_importance.to_csv(f'{result_dir}/shap_feature_importance.csv', index=False)\n",
    "\n",
    "# Guardar valores SHAP para análisis posterior\n",
    "shap_values_df = pd.DataFrame(shap_values, columns=X.columns)\n",
    "shap_values_df.to_csv(f'{result_dir}/shap_values.csv', index=False)\n",
    "\n",
    "# Crear gráfico de dependencia para las top 5 variables\n",
    "print(\"Generando gráficos de dependencia para las variables más importantes...\")\n",
    "top_features = feature_importance['feature'].head(5).tolist()\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.dependence_plot(feature, shap_values, X, show=False)\n",
    "    plt.title(f'Gráfico de Dependencia - {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_dir}/dependence_plot_{feature}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nImportancia de variables según SHAP (ordenadas de mayor a menor):\")\n",
    "print(\"=\"*80)\n",
    "print(feature_importance[['feature', 'importance_percentage']].to_string(\n",
    "    formatters={'importance_percentage': '{:.4f}%'.format}\n",
    "))\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "results = {\n",
    "    'feature_importance': {\n",
    "        'features': feature_importance['feature'].tolist(),\n",
    "        'importance_scores': feature_importance['importance'].tolist(),\n",
    "        'importance_percentages': feature_importance['importance_percentage'].tolist()\n",
    "    },\n",
    "    'top_features': top_features\n",
    "}\n",
    "\n",
    "with open(f'{result_dir}/shap_analysis_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")\n",
    "print(\"\\nVisualizaciones generadas:\")\n",
    "print(\"1. shap_importance_bar.png - Importancia general de variables\")\n",
    "print(\"2. shap_importance_beeswarm.png - Distribución del impacto de variables\")\n",
    "print(\"3. Gráficos de dependencia para las top 5 variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8d4e11-66a1-432a-a122-02c21f020a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 64648, number of negative: 1070767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1135415, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.056938 -> initscore=-2.807173\n",
      "[LightGBM] [Info] Start training from score -2.807173\n",
      "Calculando valores SHAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:448: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn('LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlaciones con Morosidad:\n",
      "Morosidad               1.000000\n",
      "RemuneracionPromedio    0.024056\n",
      "TasaBADLAR_Promedio     0.023284\n",
      "InflaciónMensual        0.018077\n",
      "Name: Morosidad, dtype: float64\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/lightgbm_analysis_20241214_222047\n",
      "\n",
      "Archivos generados:\n",
      "1. Gráficos SHAP\n",
      "2. Gráficos de dispersión\n",
      "3. Matriz de correlación\n",
      "4. Gráficos de evolución temporal (si aplica)\n",
      "5. Estadísticas descriptivas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamos2.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo\n",
    "model = lgb.LGBMClassifier(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    num_leaves=127,\n",
    "    n_estimators=900,\n",
    "    min_child_samples=10,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo LightGBM...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/lightgbm_analysis_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Calcular valores SHAP\n",
    "print(\"Calculando valores SHAP...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# 1. Summary Plot\n",
    "plt.figure(figsize=(12, len(X.columns) * 0.3))\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "plt.title(\"Importancia de Variables (SHAP)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/shap_importance_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Summary Plot (Beeswarm)\n",
    "plt.figure(figsize=(12, len(X.columns) * 0.3))\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "plt.title(\"Impacto de Variables en la Predicción (SHAP)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/shap_importance_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Análisis específico de variables seleccionadas\n",
    "variables_interes = ['TasaBADLAR_Promedio', 'InflaciónMensual', 'RemuneracionPromedio']\n",
    "\n",
    "# Gráficos de dependencia SHAP para variables específicas\n",
    "for variable in variables_interes:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.dependence_plot(variable, shap_values, X, show=False)\n",
    "    plt.title(f'Gráfico de Dependencia SHAP - {variable}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_dir}/dependence_plot_{variable}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Análisis de correlación con morosidad\n",
    "df_analisis = df_mora_prestamos[variables_interes + ['Morosidad']]\n",
    "\n",
    "# 4. Gráficos de dispersión para cada variable vs Morosidad\n",
    "for variable in variables_interes:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Crear gráfico de dispersión\n",
    "    sns.scatterplot(data=df_mora_prestamos, x=variable, y='Morosidad', alpha=0.5)\n",
    "    \n",
    "    # Agregar línea de tendencia\n",
    "    z = np.polyfit(df_mora_prestamos[variable], df_mora_prestamos['Morosidad'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df_mora_prestamos[variable], p(df_mora_prestamos[variable]), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.title(f'Relación entre {variable} y Morosidad')\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel('Morosidad')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_dir}/scatter_plot_{variable}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 5. Matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df_analisis.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.3f')\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{result_dir}/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. Gráfico de líneas temporales (si hay variable temporal)\n",
    "if 'Fecha' in df_mora_prestamos.columns:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Crear subplots para cada variable\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 20))\n",
    "    fig.suptitle('Evolución Temporal de Variables', fontsize=16)\n",
    "    \n",
    "    # Graficar cada variable\n",
    "    for idx, variable in enumerate(variables_interes):\n",
    "        axes[idx].plot(df_mora_prestamos['Fecha'], df_mora_prestamos[variable], 'b-')\n",
    "        axes[idx].set_title(f'Evolución de {variable}')\n",
    "        axes[idx].grid(True)\n",
    "        \n",
    "    # Graficar morosidad\n",
    "    axes[3].plot(df_mora_prestamos['Fecha'], df_mora_prestamos['Morosidad'], 'r-')\n",
    "    axes[3].set_title('Evolución de Morosidad')\n",
    "    axes[3].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{result_dir}/temporal_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Calcular y guardar estadísticas\n",
    "stats = {\n",
    "    'correlations': correlation_matrix['Morosidad'].to_dict(),\n",
    "    'variables_stats': df_analisis.describe().to_dict()\n",
    "}\n",
    "\n",
    "with open(f'{result_dir}/analysis_stats.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=4)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nCorrelaciones con Morosidad:\")\n",
    "print(correlation_matrix['Morosidad'].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nResultados guardados en:\", result_dir)\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"1. Gráficos SHAP\")\n",
    "print(\"2. Gráficos de dispersión\")\n",
    "print(\"3. Matriz de correlación\")\n",
    "print(\"4. Gráficos de evolución temporal (si aplica)\")\n",
    "print(\"5. Estadísticas descriptivas\")\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
