{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92cbaa9-05b5-45a1-b660-b67b907dd9ae",
   "metadata": {},
   "source": [
    "# 1. IMPORTACIÓN DE LIBRERÍAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dfd43a-4f71-4fa7-8e3b-d6a4df07fc48",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias para comenzar a trabajar con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d93bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1778a25a-2747-4f12-b844-6f4d27243110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\usuario\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c95a8e-e64e-47f6-a128-e9bd466062b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\usuario\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ef2048-6b53-4a67-97ed-4efbbdaaa2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\usuario\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43badd1-529d-4541-a30c-ce5f13baf8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\usuario\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a251cd91-46df-4f2e-87b7-8c5c5672ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from xgboost import XGBClassifier\n",
    "from subprocess import check_call\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from xgboost import XGBClassifier\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image as PImage\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598561b2-64c0-47ab-98d2-aaa24b447f4f",
   "metadata": {},
   "source": [
    "///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d16da-651f-4848-89ba-2bf6e0b0b734",
   "metadata": {},
   "source": [
    "# REGRESION LOGISTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf5eb63-7cb6-46c4-bdd3-873bda295fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando SMOTE a los datos de entrenamiento...\n",
      "Entrenando modelo de Regresión Logística...\n",
      "\n",
      "Resultados del modelo de Regresión Logística con SMOTE:\n",
      "========================================\n",
      "\n",
      "Distribución original de clases en entrenamiento:\n",
      "Clase 0: 1072714\n",
      "Clase 1: 65670\n",
      "\n",
      "Distribución después de SMOTE:\n",
      "Clase 0: 1072714\n",
      "Clase 1: 1072714\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9949\n",
      "Precision: 0.6962\n",
      "Recall: 0.9683\n",
      "Specificity: 0.9741\n",
      "F1_Score: 0.8100\n",
      "Accuracy: 0.9738\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[447841  11894]\n",
      " [   891  27254]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/logistic_regression_smote_results_20250203_234815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (roc_curve, roc_auc_score, precision_score, recall_score,\n",
    "                           f1_score, accuracy_score, confusion_matrix)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicar SMOTE a los datos de entrenamiento\n",
    "print(\"Aplicando SMOTE a los datos de entrenamiento...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Configurar y entrenar modelo\n",
    "model = LogisticRegression(\n",
    "    C=10,\n",
    "    penalty='l1',\n",
    "    class_weight='balanced',\n",
    "    max_iter=100,\n",
    "    fit_intercept=True,\n",
    "    solver='liblinear',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo de Regresión Logística...\")\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/logistic_regression_smote_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# Guardar datos ROC para comparación posterior\n",
    "roc_data = {\n",
    "    'model': 'Logistic_Regression',\n",
    "    'fpr': fpr.tolist(),\n",
    "    'tpr': tpr.tolist(),\n",
    "    'roc_auc': roc_auc,\n",
    "    'thresholds': thresholds.tolist()\n",
    "}\n",
    "\n",
    "with open(f'{result_dir}/roc_data.json', 'w') as f:\n",
    "    json.dump(roc_data, f)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - Regresión Logística con SMOTE')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Regresión Logística con SMOTE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - Regresión Logística con SMOTE')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todas las métricas y resultados\n",
    "results = {\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_distribution': {\n",
    "        'original_train': {\n",
    "            'class_0': int(sum(y_train == 0)),\n",
    "            'class_1': int(sum(y_train == 1))\n",
    "        },\n",
    "        'balanced_train': {\n",
    "            'class_0': int(sum(y_train_balanced == 0)),\n",
    "            'class_1': int(sum(y_train_balanced == 1))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{result_dir}/all_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo de Regresión Logística con SMOTE:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"\\nDistribución original de clases en entrenamiento:\")\n",
    "print(f\"Clase 0: {sum(y_train == 0)}\")\n",
    "print(f\"Clase 1: {sum(y_train == 1)}\")\n",
    "print(f\"\\nDistribución después de SMOTE:\")\n",
    "print(f\"Clase 0: {sum(y_train_balanced == 0)}\")\n",
    "print(f\"Clase 1: {sum(y_train_balanced == 1)}\")\n",
    "\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc9ee3-3960-4e12-8b2e-a1417596c66b",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e6ba8b1-d82a-4d4e-9ada-e7b533346a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Random Forest...\n",
      "\n",
      "Resultados del modelo Random Forest:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9996\n",
      "Precision: 0.9801\n",
      "Recall: 0.9669\n",
      "Specificity: 0.9988\n",
      "F1_Score: 0.9735\n",
      "Accuracy: 0.9970\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[459183    552]\n",
      " [   931  27214]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/random_forest_results_20250204_005324\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=900,\n",
    "    max_depth=30,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo Random Forest...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/random_forest_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - Random Forest')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - Random Forest')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "    'model_name': 'Random_Forest',\n",
    "    'hyperparameters': {\n",
    "        'n_estimators': 900,\n",
    "        'max_depth': 20,\n",
    "        'min_samples_split': 5,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': 'log2',\n",
    "        'class_weight': 'balanced_subsample',\n",
    "        'bootstrap': True\n",
    "    },\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_distribution': {\n",
    "        'train': {\n",
    "            'class_0': int(sum(y_train == 0)),\n",
    "            'class_1': int(sum(y_train == 1))\n",
    "        }\n",
    "    },\n",
    "    'roc_data': {\n",
    "        'fpr': fpr.tolist(),\n",
    "        'tpr': tpr.tolist(),\n",
    "        'roc_auc': roc_auc,\n",
    "        'thresholds': thresholds.tolist()\n",
    "    },\n",
    "    'sensitivity_specificity': {\n",
    "        'recall': float(metrics['Recall']),\n",
    "        'specificity': float(metrics['Specificity']),\n",
    "        'confusion_matrix_values': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo Random Forest:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b058b-5d47-4811-9075-aa700453affa",
   "metadata": {},
   "source": [
    "# REDES NEURONALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c561bf1-6907-4e62-824d-633a2692fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo de Red Neuronal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15247/15247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step\n",
      "\n",
      "Resultados del modelo Red Neuronal:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9994\n",
      "Precision: 0.9904\n",
      "Recall: 0.9748\n",
      "Specificity: 0.9994\n",
      "F1_Score: 0.9825\n",
      "Accuracy: 0.9980\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[459468    267]\n",
      " [   709  27436]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/neural_network_results_20250204_020451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                          recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "def create_model():\n",
    "   model = Sequential([\n",
    "       Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "       Dropout(0.1),\n",
    "       Dense(64, activation='relu'),\n",
    "       Dropout(0.1),\n",
    "       Dense(16, activation='relu'),\n",
    "       Dropout(0.1),\n",
    "       Dense(1, activation='sigmoid')\n",
    "   ])\n",
    "   model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "   return model\n",
    "\n",
    "print(\"Entrenando modelo de Red Neuronal...\")\n",
    "model = create_model()\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=100,\n",
    "                  verbose=0)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "   'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "   'Precision': precision_score(y_test, y_pred),\n",
    "   'Recall': recall_score(y_test, y_pred),\n",
    "   'Specificity': specificity,\n",
    "   'F1_Score': f1_score(y_test, y_pred),\n",
    "   'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/neural_network_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - Red Neuronal')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Red Neuronal')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - Red Neuronal')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "   plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "   'model_name': 'Neural_Network',\n",
    "   'hyperparameters': {\n",
    "       'architecture': [128, 64, 16],\n",
    "       'dropout_rate': 0.1,\n",
    "       'batch_size': 64,\n",
    "       'learning_rate': 0.001,\n",
    "       'epochs': 100,\n",
    "       'optimizer': 'adam',\n",
    "       'loss': 'binary_crossentropy'\n",
    "   },\n",
    "   'metrics': metrics,\n",
    "   'confusion_matrix': cm.tolist(),\n",
    "   'class_distribution': {\n",
    "       'train': {\n",
    "           'class_0': int(sum(y_train == 0)),\n",
    "           'class_1': int(sum(y_train == 1))\n",
    "       }\n",
    "   },\n",
    "   'roc_data': {\n",
    "       'fpr': fpr.tolist(),\n",
    "       'tpr': tpr.tolist(),\n",
    "       'roc_auc': roc_auc,\n",
    "       'thresholds': thresholds.tolist()\n",
    "   },\n",
    "   'sensitivity_specificity': {\n",
    "       'recall': float(metrics['Recall']),\n",
    "       'specificity': float(metrics['Specificity']),\n",
    "       'confusion_matrix_values': {\n",
    "           'tn': int(tn),\n",
    "           'fp': int(fp),\n",
    "           'fn': int(fn),\n",
    "           'tp': int(tp)\n",
    "       }\n",
    "   }\n",
    "}\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "   json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo Red Neuronal:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "   print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485061a-522d-457b-a9a0-857d111b68ac",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d498dde0-5b2b-4fce-894a-cbc49cfaaef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo XGBoost...\n",
      "\n",
      "Resultados del modelo XGBoost:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9998\n",
      "Precision: 0.9911\n",
      "Recall: 0.9770\n",
      "Specificity: 0.9995\n",
      "F1_Score: 0.9840\n",
      "Accuracy: 0.9982\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[459489    246]\n",
      " [   648  27497]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/xgboost_results_20250204_020538\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "model = xgb.XGBClassifier(\n",
    "    subsample=0.8,\n",
    "    reg_lambda=0,\n",
    "    reg_alpha=1.0,\n",
    "    n_estimators=700,\n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    gamma=0.4,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo XGBoost...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/xgboost_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - XGBoost')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - XGBoost')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - XGBoost')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "    'model_name': 'XGBoost',\n",
    "    'hyperparameters': {\n",
    "        'subsample': 0.9,\n",
    "        'reg_lambda': 0.1,\n",
    "        'reg_alpha': 1.0,\n",
    "        'n_estimators': 600,\n",
    "        'min_child_weight': 5,\n",
    "        'max_depth': 10,\n",
    "        'learning_rate': 0.1,\n",
    "        'gamma': 0,\n",
    "        'colsample_bytree': 0.6\n",
    "    },\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_distribution': {\n",
    "        'train': {\n",
    "            'class_0': int(sum(y_train == 0)),\n",
    "            'class_1': int(sum(y_train == 1))\n",
    "        }\n",
    "    },\n",
    "    'roc_data': {\n",
    "        'fpr': fpr.tolist(),\n",
    "        'tpr': tpr.tolist(),\n",
    "        'roc_auc': roc_auc,\n",
    "        'thresholds': thresholds.tolist()\n",
    "    },\n",
    "    'sensitivity_specificity': {\n",
    "        'recall': float(metrics['Recall']),\n",
    "        'specificity': float(metrics['Specificity']),\n",
    "        'confusion_matrix_values': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo XGBoost:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8764d-cab0-4159-84a5-7646ab56a91b",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16ce902-a6a8-4b9d-80cb-1603c27cf8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo Gradient Boosting...\n",
      "\n",
      "Resultados del modelo Gradient Boosting:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9995\n",
      "Precision: 0.9867\n",
      "Recall: 0.9727\n",
      "Specificity: 0.9992\n",
      "F1_Score: 0.9797\n",
      "Accuracy: 0.9977\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[459367    368]\n",
      " [   768  27377]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/gradient_boosting_results_20250204_025001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "model = GradientBoostingClassifier(\n",
    "    subsample=1.0,\n",
    "    n_estimators=700,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    max_depth=7,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo Gradient Boosting...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/gradient_boosting_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - Gradient Boosting')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - Gradient Boosting')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - Gradient Boosting')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "    'model_name': 'Gradient_Boosting',\n",
    "    'hyperparameters': {\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 500,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': 'log2',\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.05\n",
    "    },\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_distribution': {\n",
    "        'train': {\n",
    "            'class_0': int(sum(y_train == 0)),\n",
    "            'class_1': int(sum(y_train == 1))\n",
    "        }\n",
    "    },\n",
    "    'roc_data': {\n",
    "        'fpr': fpr.tolist(),\n",
    "        'tpr': tpr.tolist(),\n",
    "        'roc_auc': roc_auc,\n",
    "        'thresholds': thresholds.tolist()\n",
    "    },\n",
    "    'sensitivity_specificity': {\n",
    "        'recall': float(metrics['Recall']),\n",
    "        'specificity': float(metrics['Specificity']),\n",
    "        'confusion_matrix_values': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo Gradient Boosting:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e279b4-9712-4cb1-aaa4-a63bb6c85901",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a5c3ea-c90a-45fc-9920-62fcab2a0b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 65670, number of negative: 1072714\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 1138384, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057687 -> initscore=-2.793305\n",
      "[LightGBM] [Info] Start training from score -2.793305\n",
      "\n",
      "Resultados del modelo LightGBM:\n",
      "========================================\n",
      "\n",
      "Métricas principales:\n",
      "ROC_AUC: 0.9998\n",
      "Precision: 0.9921\n",
      "Recall: 0.9787\n",
      "Specificity: 0.9995\n",
      "F1_Score: 0.9853\n",
      "Accuracy: 0.9983\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[459515    220]\n",
      " [   600  27545]]\n",
      "\n",
      "Resultados guardados en: D:/Tesis/Definitivos/nuevo/lightgbm_results_20250204_025221\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (roc_curve, auc, roc_auc_score, precision_score, \n",
    "                           recall_score, f1_score, accuracy_score, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df_mora_prestamos = pd.read_csv('D:/Tesis/Definitivos/nuevo/df_mora_prestamospersonales.csv')\n",
    "X = df_mora_prestamos.drop('Morosidad', axis=1)\n",
    "y = df_mora_prestamos['Morosidad']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Configurar y entrenar modelo con los mejores hiperparámetros\n",
    "model = lgb.LGBMClassifier(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    num_leaves=127,\n",
    "    n_estimators=900,\n",
    "    min_child_samples=10,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo LightGBM...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular métricas\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "metrics = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "    'Precision': precision_score(y_test, y_pred),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'Specificity': specificity,\n",
    "    'F1_Score': f1_score(y_test, y_pred),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Calcular datos para curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_dir = f'D:/Tesis/Definitivos/nuevo/lightgbm_results_{timestamp}'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 1. Graficar y guardar matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión - LightGBM')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicho')\n",
    "plt.savefig(f'{result_dir}/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Graficar y guardar curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Curva ROC - LightGBM')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'{result_dir}/roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Graficar Recall y Especificidad\n",
    "plt.figure(figsize=(8, 6))\n",
    "metrics_plot = [metrics['Recall'], metrics['Specificity']]\n",
    "plt.bar(['Recall (Sensibilidad)', 'Especificidad'], metrics_plot, color=['skyblue', 'lightgreen'])\n",
    "plt.title('Recall vs Especificidad - LightGBM')\n",
    "plt.ylim([0, 1])\n",
    "for i, v in enumerate(metrics_plot):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.savefig(f'{result_dir}/recall_specificity.png')\n",
    "plt.close()\n",
    "\n",
    "# Guardar todos los resultados\n",
    "results = {\n",
    "    'model_name': 'LightGBM',\n",
    "    'hyperparameters': {\n",
    "        'subsample': 0.6,\n",
    "        'reg_lambda': 0.1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'num_leaves': 127,\n",
    "        'n_estimators': 900,\n",
    "        'min_child_samples': 10,\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'colsample_bytree': 0.6\n",
    "    },\n",
    "    'metrics': metrics,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_distribution': {\n",
    "        'train': {\n",
    "            'class_0': int(sum(y_train == 0)),\n",
    "            'class_1': int(sum(y_train == 1))\n",
    "        }\n",
    "    },\n",
    "    'roc_data': {\n",
    "        'fpr': fpr.tolist(),\n",
    "        'tpr': tpr.tolist(),\n",
    "        'roc_auc': roc_auc,\n",
    "        'thresholds': thresholds.tolist()\n",
    "    },\n",
    "    'sensitivity_specificity': {\n",
    "        'recall': float(metrics['Recall']),\n",
    "        'specificity': float(metrics['Specificity']),\n",
    "        'confusion_matrix_values': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "with open(f'{result_dir}/model_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Imprimir resultados en consola\n",
    "print(\"\\nResultados del modelo LightGBM:\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nMétricas principales:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad892d-92b7-4b13-b455-92c45c0975a5",
   "metadata": {},
   "source": [
    "# COMPARACIÓN DE RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6607011d-63ef-47a1-b00b-d9f18f158aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando resultados de los modelos...\n",
      "Cargados resultados de Logistic_Regression\n",
      "Cargados resultados de Random_Forest\n",
      "Cargados resultados de XGBoost\n",
      "Cargados resultados de LightGBM\n",
      "Cargados resultados de Neural_Network\n",
      "Cargados resultados de Gradient_Boosting\n",
      "\n",
      "Modelos encontrados: ['Logistic_Regression', 'Random_Forest', 'XGBoost', 'LightGBM', 'Neural_Network', 'Gradient_Boosting']\n",
      "\n",
      "Generando visualizaciones comparativas...\n",
      "\n",
      "Resumen de métricas:\n",
      "             Logistic_Regression  Random_Forest  XGBoost  LightGBM  \\\n",
      "ROC_AUC                   0.9883         0.9996   0.9998    0.9998   \n",
      "Precision                 0.6193         0.9801   0.9911    0.9921   \n",
      "Recall                    0.9571         0.9669   0.9770    0.9787   \n",
      "Specificity               0.9645         0.9988   0.9995    0.9995   \n",
      "F1_Score                  0.7520         0.9735   0.9840    0.9853   \n",
      "Accuracy                  0.9641         0.9970   0.9982    0.9983   \n",
      "\n",
      "             Neural_Network  Gradient_Boosting  \n",
      "ROC_AUC              0.9994             0.9995  \n",
      "Precision            0.9904             0.9867  \n",
      "Recall               0.9748             0.9727  \n",
      "Specificity          0.9994             0.9992  \n",
      "F1_Score             0.9825             0.9797  \n",
      "Accuracy             0.9980             0.9977  \n",
      "\n",
      "Visualizaciones guardadas:\n",
      "- comparison_roc_curves.png\n",
      "- comparison_metrics_heatmap.png\n",
      "- comparison_recall_specificity.png\n",
      "- comparison_confusion_matrices.png\n",
      "- metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def find_latest_results(base_dir, model_prefix):\n",
    "    \"\"\"Encuentra el directorio de resultados más reciente para cada modelo\"\"\"\n",
    "    pattern = os.path.join(base_dir, f\"{model_prefix}_results_*\")\n",
    "    dirs = glob(pattern)\n",
    "    if dirs:\n",
    "        return max(dirs, key=os.path.getctime)\n",
    "    return None\n",
    "\n",
    "def load_model_results(base_dir):\n",
    "    \"\"\"Cargar resultados de todos los modelos\"\"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    # Lista de prefijos de modelos\n",
    "    model_prefixes = [\n",
    "        'logistic_regression',\n",
    "        'random_forest',\n",
    "        'xgboost',\n",
    "        'lightgbm',\n",
    "        'neural_network',\n",
    "        'gradient_boosting'\n",
    "    ]\n",
    "    \n",
    "    for prefix in model_prefixes:\n",
    "        latest_dir = find_latest_results(base_dir, prefix)\n",
    "        if latest_dir:\n",
    "            try:\n",
    "                results_file = os.path.join(latest_dir, 'model_results.json')\n",
    "                if os.path.exists(results_file):\n",
    "                    with open(results_file, 'r') as f:\n",
    "                        results = json.load(f)\n",
    "                        model_name = results['model_name']\n",
    "                        all_results[model_name] = results\n",
    "                        print(f\"Cargados resultados de {model_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error cargando resultados de {prefix}: {str(e)}\")\n",
    "    \n",
    "    if not all_results:\n",
    "        raise ValueError(\"No se encontraron resultados de modelos\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def plot_roc_comparison(all_results):\n",
    "    \"\"\"Graficar comparación de curvas ROC\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEEAD', '#D4A5A5']\n",
    "    \n",
    "    for (model_name, results), color in zip(all_results.items(), colors):\n",
    "        fpr = np.array(results['roc_data']['fpr'])\n",
    "        tpr = np.array(results['roc_data']['tpr'])\n",
    "        roc_auc = results['roc_data']['roc_auc']\n",
    "        \n",
    "        plt.plot(fpr, tpr, color=color, lw=2,\n",
    "                label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('Tasa de Falsos Positivos', fontsize=12)\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos', fontsize=12)\n",
    "    plt.title('Comparación de Curvas ROC', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('comparison_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_comparison(all_results):\n",
    "    \"\"\"Graficar comparación de métricas principales\"\"\"\n",
    "    # Crear DataFrame con las métricas\n",
    "    metrics_data = {}\n",
    "    for model_name, results in all_results.items():\n",
    "        metrics_data[model_name] = results['metrics']\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data).T\n",
    "    \n",
    "    # Crear heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(metrics_df, annot=True, fmt='.4f', cmap='YlOrRd', center=0.5)\n",
    "    plt.title('Comparación de Métricas', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparison_metrics_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_recall_specificity_comparison(all_results):\n",
    "    \"\"\"Graficar comparación de Recall y Especificidad\"\"\"\n",
    "    models = list(all_results.keys())\n",
    "    recalls = [results['metrics']['Recall'] for results in all_results.values()]\n",
    "    specificities = [results['metrics']['Specificity'] for results in all_results.values()]\n",
    "\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    rects1 = ax.bar(x - width/2, recalls, width, label='Recall', color='skyblue')\n",
    "    rects2 = ax.bar(x + width/2, specificities, width, label='Especificidad', color='lightgreen')\n",
    "\n",
    "    ax.set_xlabel('Modelos', fontsize=12)\n",
    "    ax.set_ylabel('Valor', fontsize=12)\n",
    "    ax.set_title('Comparación de Recall y Especificidad', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.4f}',\n",
    "                       xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('comparison_recall_specificity.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrices(all_results):\n",
    "    \"\"\"Graficar todas las matrices de confusión\"\"\"\n",
    "    n_models = len(all_results)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, (model_name, results) in enumerate(all_results.items()):\n",
    "        cm = np.array(results['confusion_matrix'])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "        axes[idx].set_title(f'Matriz de Confusión - {model_name}')\n",
    "        axes[idx].set_ylabel('Real')\n",
    "        axes[idx].set_xlabel('Predicho')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparison_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    base_dir = 'D:/Tesis/Definitivos/nuevo'\n",
    "    print(\"Cargando resultados de los modelos...\")\n",
    "    \n",
    "    try:\n",
    "        all_results = load_model_results(base_dir)\n",
    "        \n",
    "        print(f\"\\nModelos encontrados: {list(all_results.keys())}\")\n",
    "        \n",
    "        print(\"\\nGenerando visualizaciones comparativas...\")\n",
    "        plot_roc_comparison(all_results)\n",
    "        plot_metrics_comparison(all_results)\n",
    "        plot_recall_specificity_comparison(all_results)\n",
    "        plot_confusion_matrices(all_results)\n",
    "        \n",
    "        # Crear tabla resumen\n",
    "        metrics_df = pd.DataFrame({name: res['metrics'] \n",
    "                                 for name, res in all_results.items()}).round(4)\n",
    "        \n",
    "        print(\"\\nResumen de métricas:\")\n",
    "        print(metrics_df)\n",
    "        metrics_df.to_csv('metrics_summary.csv')\n",
    "        \n",
    "        print(\"\\nVisualizaciones guardadas:\")\n",
    "        print(\"- comparison_roc_curves.png\")\n",
    "        print(\"- comparison_metrics_heatmap.png\")\n",
    "        print(\"- comparison_recall_specificity.png\")\n",
    "        print(\"- comparison_confusion_matrices.png\")\n",
    "        print(\"- metrics_summary.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la ejecución: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e26d3-f9a3-485f-98e6-db097ded54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
